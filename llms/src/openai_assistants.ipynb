{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620c7631",
   "metadata": {},
   "source": [
    "# OpenAI GPT Assistances #\n",
    "\n",
    "A simple example that demonstrates how to use OpenAI's Assistant API. It has a lot of similar functionality to the Completions and Responses API, but allows you to maintain chistory across sessions and provides the ability to ingest data files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4f5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da22f3d",
   "metadata": {},
   "source": [
    "## Creating a GPT Session ##\n",
    "\n",
    "I previously saved my API Key to an OS environment variable so that it's not published online\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(f\"Connecting to ChatGPT session using API key:\\n'{my_api_key}'\")\n",
    "openai_session = openai.OpenAI(api_key=my_api_key)\n",
    "session_running = not openai_session.is_closed()\n",
    "print(f\"Session established: {session_running}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf924d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "952fb5e0",
   "metadata": {},
   "source": [
    "## Uploading Custom Files ##\n",
    "\n",
    "Users can upload files to GPT Assistants that allow GPT to search their documents for answers. This is not the same as training the AI: training involves changing the weights of the underlying neural network. Instead, these files simply provide non-public information for GPT to search.\n",
    "\n",
    "Files are uploaded to OpenAI and reside in a storage area that is associated with the given API key. By default, these files are private and can only be accessed by the GPT assistant associated with the API key. Users are charged on a per-file, per-GB, per-day basis regardless of whether their assistant is active. But the fees are relatively small, on the order of 20 cents per GB per day.\n",
    "\n",
    "To avoid being overcharged, it is important to avoid uploading the same file multiple times. Check to see if the file exists in the GPT storage area before uploading another copy. This code will verify by filename only; advanced users might compare file hashes.\n",
    "\n",
    "Once a file is uploaded into the OpenAI storage area, reference it with its ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"List of files associated with my OpenAI account: \")\n",
    "remote_files = openai_session.files.list().data\n",
    "for remote_file in remote_files:\n",
    "    print(f\" -> {remote_file.filename} (ID {remote_file.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = \"internship_checklist.txt\"\n",
    "choice = input(f\"Are you sure that you want to upload the file {local_filename}? \")\n",
    "if choice.lower().startswith('y'):\n",
    "    remote_file = openai_session.files.create(\n",
    "        file=open(local_filename, \"rb\"),\n",
    "        purpose=\"assistants\"  # this is a magic value for GPT context documents\n",
    "    )\n",
    "    # purpose='assistants'\n",
    "    # purpose='batch'\n",
    "    # purpose='fine-tune'\n",
    "    # purpose='vision'\n",
    "    # purpose='user_data'\n",
    "    # purpose='evals'\n",
    "    print(f\"Uploaded file {local_filename} (ID {remote_file.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f371e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccced7af",
   "metadata": {},
   "source": [
    "## Create the Assistant ##\n",
    "\n",
    "We will create an Assistant that is tied to our OpenAI API key. It will not be publically available unless we specifically configure it that way.\n",
    "\n",
    "Assistants are similar to Files in that they persist between sessions. So you will want to double-check whether a particular assistant exists before bothering to create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d285ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"List of assistants associated with my OpenAI account:\")\n",
    "saved_assistants = openai_session.beta.assistants.list()\n",
    "for assistant in saved_assistants.data:\n",
    "    print(f\" -> {assistant.name} (ID {assistant.id}): {assistant.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.beta.assistants.delete(\"asst_tgjOhrgM3AQ2PArlQ7tMSa6G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_name = \"Marty\"\n",
    "gpt_description = \"Prof. Tallman's Assistant\"\n",
    "gpt_context = (\n",
    "    \"Marty is the mascot for Concordia Univeristy Irvine, a golden eagle. He is always \"\n",
    "    \"positive, enthusiastic, and kind. In addition to flying, he likes to surf and hang \"\n",
    "    \"out with students. He is a wise, honerable, and cultivated Christian citizen.\"\n",
    ")\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "choice = input(f\"Are you sure that you want to create a new assisstant named {gpt_name}? \")\n",
    "if choice.lower().startswith('y'):\n",
    "    assistant = openai_session.beta.assistants.create(\n",
    "        name=gpt_name,\n",
    "        description=gpt_description,\n",
    "        instructions=gpt_context,\n",
    "        model=gpt_model,\n",
    "        tools=[{\"type\": \"file_search\"}] # to work with documents\n",
    "    )\n",
    "    # {\"type\": \"function\"}\n",
    "    # {\"type\": \"file_search\"}\n",
    "    # {\"type\": \"code_interpreter\"}\n",
    "    print(f\"Created AI Assistant '{assistant.name}' ({assistant.instructions[:50]}...)\")\n",
    "\n",
    "else:\n",
    "    assistant = saved_assistants[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb65a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a937787",
   "metadata": {},
   "source": [
    "## Create a Discussion Thread ##\n",
    "\n",
    "Previously, with the simpler AI, we had to manually set the context and conversation history with every request. The Assistants API is a little easier to work with because GPT will internally keep track of these things so that all you need to do is send each prompt and read the response.\n",
    "\n",
    "### Thread Persistence ###\n",
    "\n",
    "Threads survive across OpenAI sessions, similar to files and assistants. However, the main difference is that there is no way to list or search for existing threads. You are responsible for tracking all of your own threads by thread ID. This is important to for restoring previous discussions and avoiding clutter within the user's account (admittidely, the impact of lost threads is negligible... it just annoys those with OCD tendencies). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = openai_session.beta.threads.create()\n",
    "print(f\"Created a new discussion thread '{thread.id}'\")\n",
    "print(f\"Either save this value to restore the conversation, or delete it when finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d4d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "233a98bf",
   "metadata": {},
   "source": [
    "## Running the Conversation ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ec0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Try-except-finally helps us to always delete the thread when finished\n",
    "try:\n",
    "    user_msg = input(\"\\n> \")\n",
    "\n",
    "    print(f\"Sending message to GPT...\")\n",
    "    attachments = [ { 'file_id':remote_file.id, 'tools':[{'type': 'file_search'}] } ]\n",
    "    # 'type': 'file_search'\n",
    "    # 'type': 'code_interpreter'\n",
    "    prompt = openai_session.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_msg,\n",
    "        attachments=attachments\n",
    "    )\n",
    "    response = openai_session.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id\n",
    "    )\n",
    "\n",
    "    print(f\"Waiting for GPT response...\")\n",
    "    while response.status != \"completed\":\n",
    "        time.sleep(1) # avoid checking too often\n",
    "        response = openai_session.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=response.id\n",
    "        )\n",
    "\n",
    "    # Retrieve and display the assistant's last response\n",
    "    messages = openai_session.beta.threads.messages.list(thread_id=thread.id)\n",
    "    for message in messages.data:\n",
    "        if message.role == \"assistant\":\n",
    "            print(f\"\\nAssistant: {message.content[0].text.value}\")\n",
    "            break # display the most recent response and then stop\n",
    "\n",
    "finally:\n",
    "    openai_session.beta.threads.delete(thread_id=thread.id)\n",
    "    print(f\"\\nThread '{thread.id}' has been deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

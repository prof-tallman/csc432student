{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1e2096",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Cross-Validation #\n",
    "\n",
    "The purpose of this notebook is to introduce various means of hyperparameter tuning and cross-validation.\n",
    "\n",
    "### Hyperparameter Tuning ###\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal configuration for a machine learning model. It involves testing different values of hyperparameters for a given ML algorithm and selecting the combination that maximizes performance.\n",
    "\n",
    "There are different techniques for hyperparameter tuning, many of which are built into machine learning modules like SKLearn. Some common techniques are covered in this notebook:\n",
    "* Grid Search - Exhaustively evaluates all possible hyperparameter combinations.\n",
    "* Randomized Search - A faster version of Grid Search that samples random combinations of hyperparameters.\n",
    "* Bayesian Optimization - Uses probabilistic models to find optimal hyperparameters more efficiently.\n",
    "\n",
    "### Cross-Validation ###\n",
    "\n",
    "Cross-validation is a technique to minimize overfitting and it is especially important with regard to hyperparameter tuning. The basic idea is to create many different sets of training data and to evaluate the model's cumulative performance.\n",
    "\n",
    "There are different techniques for cross-validation, many of which are built into machine learning modules like SKLearn. Some common techniques are covered in this notebook:\n",
    "* Leave-P-Out (see also Leave-One-Out) - Removes `p` samples for validation in each iteration.\n",
    "* Stratified K-Fold - Ensures that each fold maintains a balance when there are common vs rare classification labels.\n",
    "* Shuffle-Split - Randomly partitions data into multiple train-test splits.\n",
    "\n",
    "By using cross-validation, we ensure that our chosen hyperparameters generalize well to unseen data, improving the model's robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a5a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np                                                 # type: ignore\n",
    "import pandas as pd                                                # type: ignore\n",
    "import matplotlib.pyplot as plt                                    # type: ignore\n",
    "from sklearn.model_selection import (                              # type: ignore\n",
    "    train_test_split, GridSearchCV, RandomizedSearchCV, \n",
    "    LeavePOut, StratifiedKFold, ShuffleSplit)\n",
    "from sklearn.ensemble import GradientBoostingClassifier            # type: ignore\n",
    "from sklearn.svm import SVC                                        # type: ignore\n",
    "from sklearn.metrics import accuracy_score, classification_report  # type: ignore\n",
    "\n",
    "# pip install scikit-optimize\n",
    "from skopt import BayesSearchCV                                    # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaa7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fec76f4",
   "metadata": {},
   "source": [
    "## Forest Cover Type Dataset ##\n",
    "\n",
    "The Forest Cover Type Dataset is another common dataset for multi-class classification. The goal is to predict the type of forest cover based on environment factors such as elevation, soil type, and other climate-related features.\n",
    "\n",
    "It seems that I favor environmental datasets. We had earthquake and river flow for CSC 314. Now we are considering geysers, mushrooms, and forest cover in CSC 432. I guess this comes from my love for the outdoors and the appreciation of God's creative beauty. My sabbatical is coming up and my preliminary idea is to create a large skiing dataset that can be used for clustering, regression, classification, and (of course) athletic analysis.\n",
    "\n",
    "Our data originally comes from U.S. Forest Service and U.S. Geological Survey (USGS). This is the third or fourth dataset that we have used from USGS. The data is officially hosted on the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/31/covertype) although it can also be found on Kaggle and other similar websites.\n",
    "\n",
    "### Classes ###\n",
    "\n",
    "It is a large dataset with more than 500,000 samples with 54 features that are categorized into 7 different classes:\n",
    "* Spruce/Fir (label #1, and one of my personal favorites),\n",
    "* Lodgepole Pine (#2),\n",
    "* Ponderosa Pine (#3),\n",
    "* Cottonwood/Willow (#4),\n",
    "* Aspen (label #5, another favorite),\n",
    "* Douglas-Fir (#6), and\n",
    "* Krummholz (#7).\n",
    "\n",
    "### Features ###\n",
    "\n",
    "Here is a description of the 54 features. Notice that many of them are dummy variables for the soil type.\n",
    "\n",
    "|Feature Name|Description|\n",
    "|------------|-----------|\n",
    "|Elevation|Altitude in meters|\n",
    "|Aspect|Compass direction the slope faces (0-360 degrees)|\n",
    "|Slope|Steepness in degrees|\n",
    "|Horizontal Distance to Hydrology|Distance to nearest surface water (m)|\n",
    "|Vertical Distance to Hydrology|Elevation difference from nearest surface water (m)|\n",
    "|Horizontal Distance to Roadways|Distance to nearest road (m)|\n",
    "|Hillshade at 9am, Noon, 3pm|Sunlight levels at different times of the day|\n",
    "|Horizontal Distance to Fire Points|Distance to nearest wildfire ignition point (m)|\n",
    "|Wilderness Area (**4 columns**)|One-hot encoding of 4 protected areas|\n",
    "|Soil Type (**40 columns**)|One-hot encoding of 40 soil categories|\n",
    "\n",
    "The dataset is highly imbalanced with the majority of samples being Lodgepole Pine and Spruce/Fir. On a somewhat related note, we have an official Champion Lodgepole Pine in Big Bear. It has the best combination of height, circumfrence, and canopy spread in all of California and is 2nd in the US only to an Oregon tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    "column_names = (\n",
    "    [ \"Elevation\", \"Aspect\", \"Slope\",\n",
    "      \"Horizontal_Distance_To_Hydrology\",\n",
    "      \"Vertical_Distance_To_Hydrology\", \n",
    "      \"Horizontal_Distance_To_Roadways\", \n",
    "      \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \n",
    "      \"Horizontal_Distance_To_Fire_Points\"]\n",
    "      + [f\"Wilderness_Area_{i}\" for i in range(4)]\n",
    "      + [f\"Soil_Type_{i}\" for i in range(40)] \n",
    "      + [\"Cover_Type\"])\n",
    "\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c50bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for class imbalance\n",
    "df['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bdb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isna().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c9fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "df[\"target\"] = wine.target\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c40e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87550a41",
   "metadata": {},
   "source": [
    "### Validation Sets ###\n",
    "\n",
    "We need to set aside a portion of the data to use as our ***validation set***. Even though we are going to be using cross-validation to cycle through the data, it is important to still set aside a portion of the data for final testing. In this way, we have actually have three sets of data. The first two come from the 'training' data and the last one comes from the 'test' data.\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, ...)\n",
    "```\n",
    "\n",
    "#### X_train, y_train ####\n",
    "This data is used for the cross-validation. It will be split over-and-over again to create different sets of training and test data.\n",
    "* Training set: the true training data, a different subset of X_train and y_train for each cross-validation set\n",
    "* Validation set: intermediate \"test\" data, a different subset of X_train and y_train for each cross-validation set\n",
    "\n",
    "#### X_test, y_test ####\n",
    "* Test set: this data is the true test data; it is held aside from the very beginning for final score. We will not use this test data for any of the cross-validation models because that could lead to data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0372436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "X = df.drop(columns=[\"Cover_Type\"])\n",
    "y = df[\"Cover_Type\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b712bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382dcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8e832b",
   "metadata": {},
   "source": [
    "## Two New ML Algorithms ##\n",
    "\n",
    "We are going to try two new machine learning classification algorithms, Support Vector Machines (SVM) and Gradient Boost. Let's check in with ChatGPT for a description of these algorithms:\n",
    "\n",
    "### Support Vector Machines ###\n",
    "\n",
    "\"Support Vector Machines (SVM) are supervised learning algorithms used for classification and regression tasks. SVM works by finding the optimal hyperplane that best separates different classes in a dataset. It maximizes the margin (distance between the closest data points, called support vectors) to ensure better generalization. When the data is not linearly separable, SVM uses the kernel trick (e.g., polynomial or RBF kernel) to transform data into a higher-dimensional space where a linear boundary can be applied. SVMs are particularly effective in high-dimensional spaces and small datasets, but they can be computationally expensive for large datasets.\"\n",
    "\n",
    "### Gradient Boost ###\n",
    "\n",
    "\"Gradient Boosting is a machine learning method that builds a strong model by combining many weak models (usually small decision trees). It works step by step, where each new tree tries to fix the mistakes made by the previous trees. Instead of treating all mistakes equally, Gradient Boosting focuses more on errors that were hardest to correct. By doing this repeatedly, the model improves over time. This method is very powerful for complex, non-linear problems, but it needs careful tuning to avoid overfitting (memorizing the training data too much). It is commonly used in applications like fraud detection, ranking systems, and predicting customer behavior.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e933cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVM\": SVC(random_state=432),\n",
    "    \"Gradient Boost\": GradientBoostingClassifier(random_state=432)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3796dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f79dd5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal configuration for a machine learning model. It involves testing different values of hyperparameters for a given ML algorithm and selecting the combination that maximizes performance.\n",
    "\n",
    "For example, in clustering, the K-means algorithm requires the user to choose the number of clusters. We used WSSE elbow plots to find the optimum value for `k`. Similarly, the DBSCAN algorithm is depends on `min_samples` (minimum number of neighbors) and `eps` (neighborhood size). We combined the Silhouette Score, Calinski-Harabasz Index, and Davies-Bouldin Index metrics to optimize these parameters.\n",
    "\n",
    "In regression learning, we might choose a polynomial model that requires us to specify options like the polynomial degree and learning rate.\n",
    "\n",
    "And finally, with classification algorithms like K-Nearest Neighbors, the user is able to choose between various `metric` values (e.g., `\"euclidean\"` or `\"manhattan\"`) and a voting strategy using the `weights` parameter.\n",
    "\n",
    "In each of these cases, selecting the optimal hyperparameter values can significantly impact model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f5de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will compare Gradient Boost and Support Vector Machine, two new ML algorithms\n",
    "param_grids = {\n",
    "    'Gradient Boost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f1f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da9f5378",
   "metadata": {},
   "source": [
    "### Cross-Validation ###\n",
    "\n",
    "Cross-validation is a technique to minimize overfitting and it is especially important with regard to hyperparameter tuning. The basic idea is to create many different sets of training data and to evaluate the model's cumulative performance.\n",
    "\n",
    "Think back to how we performed hyperparameter tuning. We basically tried a bunch of different parameter values and then found which combination gave the highest accuracy score. One of the potential problems with this approach is that it is prone to overfitting. The best parameters are only \"best\" for the chosen train-test split. A different set of training data might have led us to choose different hyperparameters. This happens because the model's performance may vary depending on the data split, leading to inconsistent hyperparameter selection.\n",
    "\n",
    "Cross-validation mitigates this by repeatedly training and evaluating the model on different train-test splits, producing a more reliable estimate of model performance. The final evaluation metric is averaged over multiple train-test splits, providing a more reliable estimate of the model's true performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c40ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three cross-validation techniques\n",
    "cv_methods = {\n",
    "    \"Shuffle-Split\": ShuffleSplit(n_splits=10, test_size=0.2, random_state=123),\n",
    "    \"Stratified K-Fold\": StratifiedKFold(n_splits=5, shuffle=True, random_state=123),\n",
    "    #\"Leave-P-Out\": LeavePOut(p=2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474cd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae80b4a",
   "metadata": {},
   "source": [
    "## Evaluating the Models ##\n",
    "\n",
    "The final step is to create and validate (test) all of the models, keeping track of the best performers.\n",
    "\n",
    "We're going to find that the wine dataset is relatively small and each class is fairly easy to predict, so the accuracy of each cross-validation method will be roughly the same, though there may be some small difference in the values. We had to keep the dataset simple in order for the cross-validation techniques to finish in a reasonable time on my little laptop. Had we more processing power, we could have analyzed a larger and more complex dataset, where the differences would be more pronounced.\n",
    "\n",
    "The key to notice here is the differnce in execution time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1525af3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boost...\n",
      "  Using Shuffle-Split cross-validation\n",
      "    Grid Search  (41.47s): 0.94 accuracy with {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "    Rnd Search   ( 3.45s): 0.97 accuracy with {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.2}\n",
      "    Bayes Search ( 9.45s): 0.94 accuracy with OrderedDict({'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200})\n",
      "  Using Stratified K-Fold cross-validation\n",
      "    Grid Search  ( 7.54s): 0.94 accuracy with {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "    Rnd Search   ( 2.04s): 0.94 accuracy with {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "    Bayes Search ( 6.48s): 0.94 accuracy with OrderedDict({'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100})\n",
      "Training SVM...\n",
      "  Using Shuffle-Split cross-validation\n",
      "    Grid Search  ( 0.77s): 0.97 accuracy with {'C': 0.1, 'kernel': 'linear'}\n",
      "    Rnd Search   ( 0.65s): 0.97 accuracy with {'kernel': 'linear', 'C': 0.1}\n",
      "    Bayes Search ( 2.33s): 0.97 accuracy with OrderedDict({'C': 0.1, 'kernel': 'linear'})\n",
      "  Using Stratified K-Fold cross-validation\n",
      "    Grid Search  ( 0.40s): 0.97 accuracy with {'C': 0.1, 'kernel': 'linear'}\n",
      "    Rnd Search   ( 0.63s): 0.97 accuracy with {'kernel': 'linear', 'C': 1}\n",
      "    Bayes Search ( 1.63s): 0.97 accuracy with OrderedDict({'C': 0.1, 'kernel': 'linear'})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform hyperparameter tuning with different cross-validation methods\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    \n",
    "    for cv_name, cv_method in cv_methods.items():\n",
    "        print(f\"  Using {cv_name} cross-validation\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grids[model_name], \n",
    "            cv=cv_method, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        print(f\"    Grid Search  ({end_time - start_time:5.2f}s): {accuracy_score(y_test, y_pred):.2f} accuracy with {grid_search.best_params_}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, param_grids[model_name], \n",
    "            cv=cv_method, scoring='accuracy', \n",
    "            n_iter=5, random_state=17, n_jobs=-1)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        y_pred = random_search.best_estimator_.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        print(f\"    Rnd Search   ({end_time - start_time:5.2f}s): {accuracy_score(y_test, y_pred):.2f} accuracy with {random_search.best_params_}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        bayes_search = BayesSearchCV(\n",
    "            model, param_grids[model_name], \n",
    "            cv=cv_method, scoring='accuracy', \n",
    "            n_iter=10, random_state=17, n_jobs=-1)\n",
    "        bayes_search.fit(X_train, y_train)\n",
    "        y_pred = bayes_search.best_estimator_.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        print(f\"    Bayes Search ({end_time - start_time:5.2f}s): {accuracy_score(y_test, y_pred):.2f} accuracy with {bayes_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae24576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "334d3f62",
   "metadata": {},
   "source": [
    "### Analyzing Results ###\n",
    "\n",
    "We can dig deeper into the results by comparing the accuracy of each test using the `cv_results_` parameter. There are several different metrics available, mostly related to accuracy score and execution time. We will look into the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46290dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'kernel': 'linear', 'C': 1}, {'kernel': 'rbf', 'C': 1}, {'kernel': 'linear', 'C': 10}, {'kernel': 'linear', 'C': 0.1}, {'kernel': 'rbf', 'C': 10}]\n",
      "[0.95763547 0.67586207 0.9364532  0.95763547 0.72512315]\n",
      "[1 5 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print(random_search.cv_results_['params'])\n",
    "print(random_search.cv_results_['mean_test_score'])\n",
    "print(random_search.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b06e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.764%: {'kernel': 'linear', 'C': 1}\n",
      "Accuracy 95.764%: {'kernel': 'linear', 'C': 0.1}\n",
      "Accuracy 93.645%: {'kernel': 'linear', 'C': 10}\n",
      "Accuracy 72.512%: {'kernel': 'rbf', 'C': 10}\n",
      "Accuracy 67.586%: {'kernel': 'rbf', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "combined = zip(random_search.cv_results_['params'], random_search.cv_results_['mean_test_score'])\n",
    "combined = sorted(list(combined), key=lambda x: x[1], reverse=True)\n",
    "for param, score in combined:\n",
    "    print(f\"Accuracy {100*score:.3f}%: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1ac5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.764%: {'C': 0.1, 'kernel': 'linear'}\n",
      "Accuracy 95.764%: {'C': 1, 'kernel': 'linear'}\n",
      "Accuracy 93.645%: {'C': 10, 'kernel': 'linear'}\n",
      "Accuracy 72.512%: {'C': 10, 'kernel': 'rbf'}\n",
      "Accuracy 67.586%: {'C': 1, 'kernel': 'rbf'}\n",
      "Accuracy 66.232%: {'C': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "combined = zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'])\n",
    "combined = sorted(list(combined), key=lambda x: x[1], reverse=True)\n",
    "for param, score in combined:\n",
    "    print(f\"Accuracy {100*score:.3f}%: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37395ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593a433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4235b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae2737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620c7631",
   "metadata": {},
   "source": [
    "# 2023 Superbowl Score Predictor #\n",
    "\n",
    "This is a simple regression model to predict the Superbowl score. It uses a two-feature dataset from the 2023 regular season. Playoff results are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1a12ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b4f5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5da22f3d",
   "metadata": {},
   "source": [
    "## Collecting and Normalizing Data ##\n",
    "\n",
    "For the purposes of this demonstration, we are going to breeze over data collection and use a local CSV file. The CSV file was created by hand, earlier in the semester, using 2023 data from the [NFL](https://nfl.com/stats) website.\n",
    "\n",
    "The data includes two input features that are on very different scales. The first feature is Opponent Points Against and it is the total number of points scored against our opponent for the entire year. Typical values are in the 300-400 range and higher numbers indicate that our opponent had a poor defense (so we would expect to score more often). The second feature is Opponent Turnovers and these values are in the 20-30 range. These numbers give the total number of times that our opponent's offense fumbled the ball or threw an interception. Higher numbers indicate that our offense should expect more posessions (so we would expect to score more often).\n",
    "\n",
    "The Points Against and Turnovers features are on different scales, which might cause our model to overemphasize the data with higher numbers. To avoid this, we will use a MinMaxScaler to normalize the data to a floating point number between 0-1, spreading the data out evenly between these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a053b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_nfl_stats.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Opponent Points Against':'OppPA', 'Opponent Turnovers':'OppTO'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['OppPA', 'OppTO']] = scaler.fit_transform(df[['OppPA', 'OppTO']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f9ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "952fb5e0",
   "metadata": {},
   "source": [
    "## Encoding Non-Numeric Features ##\n",
    "\n",
    "Notice that our model contains data for the Chiefs and the 49ers and these samples are differentiated from each other based on a string. These teams have different offenses and we want to make sure that our model keeps the teams separate in its calculations. One idea would be to separate the data and create two different models: one for the Chiefs and another for the 49ers. However, separating the data means that we lose datapoints. And the fact is, there is a football-is-football aspect to the game results that are common to all teams. So let's build one single model but use the \"Teams\" feature to account for the difference in rosters and coaching. But how do we use a string in a regression equation?\n",
    "\n",
    "One of the most common ways to account for categorical information in a machine learning model is using one-hot encoding. This encoding technique creates a binary feature for every possible string value. It assigns a 1 to whichever feature corresponds to the string value and a 0 for the other, non-matching features. So, if our data included all 32 NFL teams, we would transform the data from 1 feature with 32 values to 32 binary features. At some point, all of these features can produce \"The Curse of Dimensionality\" which slows down processing and leads to overfit. There are techniques to avoid TCD, but we will save those for later.\n",
    "\n",
    "There are other encoding techniques like ordinal encoding that simple assign a unique value to represent each category, while keeping the data within a single feature. This works well when there is a natural order to the data like (cold, cool, room temp, warm, hot) or (low, medium, high). But ordinal encoding can cause problems if the data has no underlying sequence, such as the case of football team names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, dtype=np.uint8)\n",
    "encoded = encoder.fit_transform(df[['Team']])\n",
    "columns = encoder.get_feature_names_out(['Team'])\n",
    "\n",
    "print(columns)\n",
    "print(encoded[:3])\n",
    "print('...')\n",
    "print(encoded[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff50c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pd.DataFrame(encoded, columns=columns)\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, encoded], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f371e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccced7af",
   "metadata": {},
   "source": [
    "## Create a Model ##\n",
    "\n",
    "We will use a multilinear regression model to predict the Superbowl scores. Multilinear means that we are measuring a linear relationship between the inputs and the output, but there is more than one independent variable (feature). The `LinearRegression` object works the same whether you use it with a single feature or many (phew!).\n",
    "\n",
    "In order to test the accuracy of our model, we will hold back a few of the games from the training model. The `train_test_split` function will separate the inputs X and the output y simultaneously, randomly choosing the samples to hold back for training but making sure to choose the same X rows and y rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d285ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Team_49ers', 'Team_Chiefs', 'OppPA', 'OppTO']]\n",
    "y = df[['Points']]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dac84a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c16ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb65a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a937787",
   "metadata": {},
   "source": [
    "## Score the Model ##\n",
    "\n",
    "There are a variety of metrics to score the quality of a regression model. Three common metrics are *Mean Absolute Error*, *Mean Squared Error*, and $R^2$ Error.\n",
    "* Mean Absolute Error (**MAE**): Scoring single model or models with same output scales, don't care about extreme outlier predictions. Score directly connected to output values.\n",
    "* Mean Squared Error (**MSE**): Similar to MAE but want to highlight models with extreme outliers. Range of scores may not correspond to the output range.\n",
    "* $R^2$ Error (**R2**): Standardized score with -$\\infty$ being negative scores being really poor and 1 being perfect score. Score of 0 is equal to just picking the mean y-value for your prediction.\n",
    "\n",
    "We will use MAE so that our score metric represents points from the game.\n",
    "\n",
    "If we are unhappy with the score, we can go back and change the features or parameters used in the model. This sort of evaluate-modify feedback loop is important, but it is also one of the easiest ways to introduce leakage or bias in a way that overfits our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_score = mean_absolute_error(y_test, y_pred)\n",
    "print(mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d4d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "233a98bf",
   "metadata": {},
   "source": [
    "## Predict the Superbowl Winner ##\n",
    "\n",
    "Now that we are happy with our model, let's make a prediction with the Superbowl teams facing off against each other. These statistics weren't in our original data and at this point, it's probably easiest to just manually create the appropriate arrays following the same order as our original input features in X.\n",
    "\n",
    "By the way, we know the result of the Chiefs-49ers Superbowl. Hopefully our model predicts the Chief's winning 38-35.\n",
    "\n",
    "### 49ers vs Chiefs ###\n",
    "|Team|Opponent Points Against|Opponent Turnovers|\n",
    "|----|-----------------------|------------------|\n",
    "|49ers|294 (Chiefs had good defense|28 (Chief's were turnover prone)|\n",
    "|Chiefs|298 (49ers also had a good defense)|18 (49ers protected the football)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ec0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need for OHE because we created the data manually\n",
    "X_real = pd.DataFrame({'Team_49ers':[1, 0],\n",
    "                  'Team_Chiefs':[0, 1],\n",
    "                  'OppPA':[294, 298],\n",
    "                  'OppTO':[28, 18]})\n",
    "X_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa33794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real[['OppPA', 'OppTO']] = scaler.transform(X_real[['OppPA', 'OppTO']])\n",
    "X_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5541cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "superbowl_scores = model.predict(X_real)\n",
    "superbowl_scores = np.round(superbowl_scores).astype(np.uint8)\n",
    "print(f\"2023 SUPERBOWL PREDICITON\")\n",
    "print(f\"49ers: {superbowl_scores[0]}\")\n",
    "print(f\"Chiefs: {superbowl_scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da66ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00e9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
